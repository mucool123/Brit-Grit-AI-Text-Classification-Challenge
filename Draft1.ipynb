{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79963548-f05e-44c5-9087-12069b2b6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('training_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25091ecd-6693-4541-b518-0d9cd04f211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_num</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>0.216665</td>\n",
       "      <td>-0.737486</td>\n",
       "      <td>0.243974</td>\n",
       "      <td>-0.214145</td>\n",
       "      <td>-0.561164</td>\n",
       "      <td>1.007393</td>\n",
       "      <td>-0.341624</td>\n",
       "      <td>-1.833031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426835</td>\n",
       "      <td>-0.259632</td>\n",
       "      <td>-1.536571</td>\n",
       "      <td>-0.823593</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>-0.023658</td>\n",
       "      <td>0.275614</td>\n",
       "      <td>-0.484724</td>\n",
       "      <td>1.646305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.057045</td>\n",
       "      <td>-2.433794</td>\n",
       "      <td>0.161713</td>\n",
       "      <td>-0.412046</td>\n",
       "      <td>0.883919</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>-1.268735</td>\n",
       "      <td>-0.217655</td>\n",
       "      <td>2.224833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325232</td>\n",
       "      <td>0.189428</td>\n",
       "      <td>0.524676</td>\n",
       "      <td>0.174621</td>\n",
       "      <td>0.439760</td>\n",
       "      <td>2.107173</td>\n",
       "      <td>-0.046571</td>\n",
       "      <td>-0.679445</td>\n",
       "      <td>-0.828227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965676</td>\n",
       "      <td>-1.271543</td>\n",
       "      <td>-1.254102</td>\n",
       "      <td>0.962798</td>\n",
       "      <td>1.014737</td>\n",
       "      <td>1.103707</td>\n",
       "      <td>-0.263757</td>\n",
       "      <td>1.420545</td>\n",
       "      <td>1.989763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322874</td>\n",
       "      <td>0.434038</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>0.635286</td>\n",
       "      <td>-0.010914</td>\n",
       "      <td>1.203948</td>\n",
       "      <td>-1.224092</td>\n",
       "      <td>-0.095281</td>\n",
       "      <td>0.161586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.275498</td>\n",
       "      <td>-2.966496</td>\n",
       "      <td>0.199029</td>\n",
       "      <td>1.032070</td>\n",
       "      <td>2.353690</td>\n",
       "      <td>-0.381039</td>\n",
       "      <td>-0.322293</td>\n",
       "      <td>-0.660425</td>\n",
       "      <td>1.927430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.114838</td>\n",
       "      <td>-0.339488</td>\n",
       "      <td>3.116455</td>\n",
       "      <td>-0.047012</td>\n",
       "      <td>0.511633</td>\n",
       "      <td>0.904325</td>\n",
       "      <td>0.598084</td>\n",
       "      <td>-1.555691</td>\n",
       "      <td>-1.075680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.164959</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>0.689579</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>-0.094361</td>\n",
       "      <td>-0.610501</td>\n",
       "      <td>-0.735094</td>\n",
       "      <td>-0.289203</td>\n",
       "      <td>-0.390993</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.037096</td>\n",
       "      <td>-0.439526</td>\n",
       "      <td>-1.045375</td>\n",
       "      <td>-0.720963</td>\n",
       "      <td>1.456124</td>\n",
       "      <td>-0.763690</td>\n",
       "      <td>-1.218395</td>\n",
       "      <td>0.488883</td>\n",
       "      <td>0.409039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   1   0.220794   0.216665  -0.737486   0.243974  -0.214145  -0.561164   \n",
       "1   2   0.057045  -2.433794   0.161713  -0.412046   0.883919   0.082726   \n",
       "2   3   0.965676  -1.271543  -1.254102   0.962798   1.014737   1.103707   \n",
       "3   4  -0.275498  -2.966496   0.199029   1.032070   2.353690  -0.381039   \n",
       "4   5  -1.164959   0.985703   0.689579   0.049533  -0.094361  -0.610501   \n",
       "\n",
       "   feature_6  feature_7  feature_8  ...  feature_761  feature_762  \\\n",
       "0   1.007393  -0.341624  -1.833031  ...    -0.426835    -0.259632   \n",
       "1  -1.268735  -0.217655   2.224833  ...     0.325232     0.189428   \n",
       "2  -0.263757   1.420545   1.989763  ...    -0.322874     0.434038   \n",
       "3  -0.322293  -0.660425   1.927430  ...     1.114838    -0.339488   \n",
       "4  -0.735094  -0.289203  -0.390993  ...    -1.037096    -0.439526   \n",
       "\n",
       "   feature_763  feature_764  feature_765  feature_766  feature_767  \\\n",
       "0    -1.536571    -0.823593     0.034862    -0.023658     0.275614   \n",
       "1     0.524676     0.174621     0.439760     2.107173    -0.046571   \n",
       "2     0.751449     0.635286    -0.010914     1.203948    -1.224092   \n",
       "3     3.116455    -0.047012     0.511633     0.904325     0.598084   \n",
       "4    -1.045375    -0.720963     1.456124    -0.763690    -1.218395   \n",
       "\n",
       "   word_count  punc_num  ind  \n",
       "0   -0.484724  1.646305    0  \n",
       "1   -0.679445 -0.828227    0  \n",
       "2   -0.095281  0.161586    0  \n",
       "3   -1.555691 -1.075680    0  \n",
       "4    0.488883  0.409039    0  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba88be18-3871-454e-bcb7-51d10cb45675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_num</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "      <td>11144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5572.500000</td>\n",
       "      <td>0.146012</td>\n",
       "      <td>-0.273505</td>\n",
       "      <td>-0.666907</td>\n",
       "      <td>-0.415562</td>\n",
       "      <td>-0.230934</td>\n",
       "      <td>-0.270790</td>\n",
       "      <td>-0.039869</td>\n",
       "      <td>-0.037003</td>\n",
       "      <td>0.101543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274985</td>\n",
       "      <td>0.687529</td>\n",
       "      <td>0.269849</td>\n",
       "      <td>0.199639</td>\n",
       "      <td>0.443093</td>\n",
       "      <td>0.078578</td>\n",
       "      <td>-0.062243</td>\n",
       "      <td>29.978643</td>\n",
       "      <td>7.347003</td>\n",
       "      <td>0.098708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3217.140034</td>\n",
       "      <td>0.389374</td>\n",
       "      <td>0.382566</td>\n",
       "      <td>0.432605</td>\n",
       "      <td>0.745149</td>\n",
       "      <td>0.583487</td>\n",
       "      <td>0.388663</td>\n",
       "      <td>0.292493</td>\n",
       "      <td>0.246509</td>\n",
       "      <td>0.503054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406760</td>\n",
       "      <td>0.431843</td>\n",
       "      <td>0.545066</td>\n",
       "      <td>0.304694</td>\n",
       "      <td>0.365657</td>\n",
       "      <td>0.551214</td>\n",
       "      <td>0.300848</td>\n",
       "      <td>10.271548</td>\n",
       "      <td>4.041350</td>\n",
       "      <td>0.298283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.633110</td>\n",
       "      <td>-1.971542</td>\n",
       "      <td>-2.505377</td>\n",
       "      <td>-4.280401</td>\n",
       "      <td>-2.413613</td>\n",
       "      <td>-1.514833</td>\n",
       "      <td>-1.427118</td>\n",
       "      <td>-1.036038</td>\n",
       "      <td>-1.779871</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.765492</td>\n",
       "      <td>-1.723701</td>\n",
       "      <td>-1.506003</td>\n",
       "      <td>-1.272904</td>\n",
       "      <td>-1.467510</td>\n",
       "      <td>-1.605773</td>\n",
       "      <td>-1.085949</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2786.750000</td>\n",
       "      <td>-0.111816</td>\n",
       "      <td>-0.517288</td>\n",
       "      <td>-0.954874</td>\n",
       "      <td>-0.891329</td>\n",
       "      <td>-0.633606</td>\n",
       "      <td>-0.536751</td>\n",
       "      <td>-0.229016</td>\n",
       "      <td>-0.197038</td>\n",
       "      <td>-0.236033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.392865</td>\n",
       "      <td>-0.125641</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.208861</td>\n",
       "      <td>-0.303969</td>\n",
       "      <td>-0.273816</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5572.500000</td>\n",
       "      <td>0.161513</td>\n",
       "      <td>-0.261028</td>\n",
       "      <td>-0.673000</td>\n",
       "      <td>-0.415641</td>\n",
       "      <td>-0.244129</td>\n",
       "      <td>-0.281473</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>-0.038384</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256874</td>\n",
       "      <td>0.683075</td>\n",
       "      <td>0.213906</td>\n",
       "      <td>0.205270</td>\n",
       "      <td>0.461389</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>-0.074150</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8358.250000</td>\n",
       "      <td>0.418461</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>-0.381686</td>\n",
       "      <td>0.078408</td>\n",
       "      <td>0.168207</td>\n",
       "      <td>-0.018891</td>\n",
       "      <td>0.157572</td>\n",
       "      <td>0.117311</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535327</td>\n",
       "      <td>0.981356</td>\n",
       "      <td>0.634109</td>\n",
       "      <td>0.400167</td>\n",
       "      <td>0.692926</td>\n",
       "      <td>0.405299</td>\n",
       "      <td>0.129446</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11144.000000</td>\n",
       "      <td>1.378549</td>\n",
       "      <td>1.376324</td>\n",
       "      <td>1.392311</td>\n",
       "      <td>2.184251</td>\n",
       "      <td>1.659698</td>\n",
       "      <td>1.667419</td>\n",
       "      <td>1.070739</td>\n",
       "      <td>1.320982</td>\n",
       "      <td>2.456948</td>\n",
       "      <td>...</td>\n",
       "      <td>1.987709</td>\n",
       "      <td>1.965830</td>\n",
       "      <td>2.582598</td>\n",
       "      <td>1.375909</td>\n",
       "      <td>1.879438</td>\n",
       "      <td>2.579186</td>\n",
       "      <td>1.674109</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     feature_0     feature_1     feature_2     feature_3  \\\n",
       "count  11144.000000  11144.000000  11144.000000  11144.000000  11144.000000   \n",
       "mean    5572.500000      0.146012     -0.273505     -0.666907     -0.415562   \n",
       "std     3217.140034      0.389374      0.382566      0.432605      0.745149   \n",
       "min        1.000000     -1.633110     -1.971542     -2.505377     -4.280401   \n",
       "25%     2786.750000     -0.111816     -0.517288     -0.954874     -0.891329   \n",
       "50%     5572.500000      0.161513     -0.261028     -0.673000     -0.415641   \n",
       "75%     8358.250000      0.418461     -0.016541     -0.381686      0.078408   \n",
       "max    11144.000000      1.378549      1.376324      1.392311      2.184251   \n",
       "\n",
       "          feature_4     feature_5     feature_6     feature_7     feature_8  \\\n",
       "count  11144.000000  11144.000000  11144.000000  11144.000000  11144.000000   \n",
       "mean      -0.230934     -0.270790     -0.039869     -0.037003      0.101543   \n",
       "std        0.583487      0.388663      0.292493      0.246509      0.503054   \n",
       "min       -2.413613     -1.514833     -1.427118     -1.036038     -1.779871   \n",
       "25%       -0.633606     -0.536751     -0.229016     -0.197038     -0.236033   \n",
       "50%       -0.244129     -0.281473     -0.036129     -0.038384      0.068244   \n",
       "75%        0.168207     -0.018891      0.157572      0.117311      0.399803   \n",
       "max        1.659698      1.667419      1.070739      1.320982      2.456948   \n",
       "\n",
       "       ...   feature_761   feature_762   feature_763   feature_764  \\\n",
       "count  ...  11144.000000  11144.000000  11144.000000  11144.000000   \n",
       "mean   ...      0.274985      0.687529      0.269849      0.199639   \n",
       "std    ...      0.406760      0.431843      0.545066      0.304694   \n",
       "min    ...     -1.765492     -1.723701     -1.506003     -1.272904   \n",
       "25%    ...     -0.000389      0.392865     -0.125641      0.000539   \n",
       "50%    ...      0.256874      0.683075      0.213906      0.205270   \n",
       "75%    ...      0.535327      0.981356      0.634109      0.400167   \n",
       "max    ...      1.987709      1.965830      2.582598      1.375909   \n",
       "\n",
       "        feature_765   feature_766   feature_767    word_count      punc_num  \\\n",
       "count  11144.000000  11144.000000  11144.000000  11144.000000  11144.000000   \n",
       "mean       0.443093      0.078578     -0.062243     29.978643      7.347003   \n",
       "std        0.365657      0.551214      0.300848     10.271548      4.041350   \n",
       "min       -1.467510     -1.605773     -1.085949      5.000000      0.000000   \n",
       "25%        0.208861     -0.303969     -0.273816     22.000000      4.000000   \n",
       "50%        0.461389      0.021472     -0.074150     30.000000      7.000000   \n",
       "75%        0.692926      0.405299      0.129446     38.000000     10.000000   \n",
       "max        1.879438      2.579186      1.674109     57.000000     27.000000   \n",
       "\n",
       "                ind  \n",
       "count  11144.000000  \n",
       "mean       0.098708  \n",
       "std        0.298283  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 772 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()\n",
    "#train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d724075-6d8c-442b-95d9-515d941383b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2786.00000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "      <td>2786.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1393.50000</td>\n",
       "      <td>0.136457</td>\n",
       "      <td>-0.282554</td>\n",
       "      <td>-0.682635</td>\n",
       "      <td>-0.438153</td>\n",
       "      <td>-0.227907</td>\n",
       "      <td>-0.252954</td>\n",
       "      <td>-0.057335</td>\n",
       "      <td>-0.046841</td>\n",
       "      <td>0.125323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653606</td>\n",
       "      <td>0.269816</td>\n",
       "      <td>0.687491</td>\n",
       "      <td>0.274532</td>\n",
       "      <td>0.195974</td>\n",
       "      <td>0.430616</td>\n",
       "      <td>0.090058</td>\n",
       "      <td>-0.063190</td>\n",
       "      <td>29.622039</td>\n",
       "      <td>7.235822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>804.39325</td>\n",
       "      <td>0.391062</td>\n",
       "      <td>0.379557</td>\n",
       "      <td>0.435319</td>\n",
       "      <td>0.734360</td>\n",
       "      <td>0.587383</td>\n",
       "      <td>0.398449</td>\n",
       "      <td>0.295156</td>\n",
       "      <td>0.252873</td>\n",
       "      <td>0.508362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567650</td>\n",
       "      <td>0.403058</td>\n",
       "      <td>0.445361</td>\n",
       "      <td>0.556459</td>\n",
       "      <td>0.300994</td>\n",
       "      <td>0.375159</td>\n",
       "      <td>0.568711</td>\n",
       "      <td>0.307806</td>\n",
       "      <td>10.283190</td>\n",
       "      <td>3.986695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.677159</td>\n",
       "      <td>-1.563449</td>\n",
       "      <td>-2.180102</td>\n",
       "      <td>-3.236507</td>\n",
       "      <td>-2.161405</td>\n",
       "      <td>-1.354988</td>\n",
       "      <td>-1.022402</td>\n",
       "      <td>-1.025329</td>\n",
       "      <td>-1.406084</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.499019</td>\n",
       "      <td>-1.149980</td>\n",
       "      <td>-1.238533</td>\n",
       "      <td>-1.741369</td>\n",
       "      <td>-0.932317</td>\n",
       "      <td>-1.348983</td>\n",
       "      <td>-1.604238</td>\n",
       "      <td>-0.957339</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>697.25000</td>\n",
       "      <td>-0.118078</td>\n",
       "      <td>-0.528972</td>\n",
       "      <td>-0.975703</td>\n",
       "      <td>-0.902200</td>\n",
       "      <td>-0.628825</td>\n",
       "      <td>-0.540910</td>\n",
       "      <td>-0.244050</td>\n",
       "      <td>-0.202107</td>\n",
       "      <td>-0.226361</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.047837</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.390471</td>\n",
       "      <td>-0.115666</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>-0.297254</td>\n",
       "      <td>-0.282540</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1393.50000</td>\n",
       "      <td>0.151619</td>\n",
       "      <td>-0.264762</td>\n",
       "      <td>-0.686354</td>\n",
       "      <td>-0.464958</td>\n",
       "      <td>-0.249773</td>\n",
       "      <td>-0.261409</td>\n",
       "      <td>-0.052723</td>\n",
       "      <td>-0.052144</td>\n",
       "      <td>0.097662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654728</td>\n",
       "      <td>0.247112</td>\n",
       "      <td>0.680915</td>\n",
       "      <td>0.221286</td>\n",
       "      <td>0.199057</td>\n",
       "      <td>0.455588</td>\n",
       "      <td>0.036784</td>\n",
       "      <td>-0.076090</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2089.75000</td>\n",
       "      <td>0.412776</td>\n",
       "      <td>-0.029236</td>\n",
       "      <td>-0.403831</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>0.182105</td>\n",
       "      <td>0.012003</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>0.438421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247197</td>\n",
       "      <td>0.521877</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.646440</td>\n",
       "      <td>0.391480</td>\n",
       "      <td>0.688687</td>\n",
       "      <td>0.421393</td>\n",
       "      <td>0.134562</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2786.00000</td>\n",
       "      <td>1.204501</td>\n",
       "      <td>1.009650</td>\n",
       "      <td>1.234603</td>\n",
       "      <td>2.021932</td>\n",
       "      <td>1.605382</td>\n",
       "      <td>1.392598</td>\n",
       "      <td>0.884735</td>\n",
       "      <td>1.301235</td>\n",
       "      <td>2.255295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.299061</td>\n",
       "      <td>2.040515</td>\n",
       "      <td>1.873001</td>\n",
       "      <td>2.476322</td>\n",
       "      <td>1.086836</td>\n",
       "      <td>1.619909</td>\n",
       "      <td>2.709688</td>\n",
       "      <td>1.624837</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID    feature_0    feature_1    feature_2    feature_3  \\\n",
       "count  2786.00000  2786.000000  2786.000000  2786.000000  2786.000000   \n",
       "mean   1393.50000     0.136457    -0.282554    -0.682635    -0.438153   \n",
       "std     804.39325     0.391062     0.379557     0.435319     0.734360   \n",
       "min       1.00000    -1.677159    -1.563449    -2.180102    -3.236507   \n",
       "25%     697.25000    -0.118078    -0.528972    -0.975703    -0.902200   \n",
       "50%    1393.50000     0.151619    -0.264762    -0.686354    -0.464958   \n",
       "75%    2089.75000     0.412776    -0.029236    -0.403831     0.050050   \n",
       "max    2786.00000     1.204501     1.009650     1.234603     2.021932   \n",
       "\n",
       "         feature_4    feature_5    feature_6    feature_7    feature_8  ...  \\\n",
       "count  2786.000000  2786.000000  2786.000000  2786.000000  2786.000000  ...   \n",
       "mean     -0.227907    -0.252954    -0.057335    -0.046841     0.125323  ...   \n",
       "std       0.587383     0.398449     0.295156     0.252873     0.508362  ...   \n",
       "min      -2.161405    -1.354988    -1.022402    -1.025329    -1.406084  ...   \n",
       "25%      -0.628825    -0.540910    -0.244050    -0.202107    -0.226361  ...   \n",
       "50%      -0.249773    -0.261409    -0.052723    -0.052144     0.097662  ...   \n",
       "75%       0.182105     0.012003     0.145749     0.108026     0.438421  ...   \n",
       "max       1.605382     1.392598     0.884735     1.301235     2.255295  ...   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "count  2786.000000  2786.000000  2786.000000  2786.000000  2786.000000   \n",
       "mean     -0.653606     0.269816     0.687491     0.274532     0.195974   \n",
       "std       0.567650     0.403058     0.445361     0.556459     0.300994   \n",
       "min      -3.499019    -1.149980    -1.238533    -1.741369    -0.932317   \n",
       "25%      -1.047837    -0.001815     0.390471    -0.115666     0.004765   \n",
       "50%      -0.654728     0.247112     0.680915     0.221286     0.199057   \n",
       "75%      -0.247197     0.521877     0.995831     0.646440     0.391480   \n",
       "max       1.299061     2.040515     1.873001     2.476322     1.086836   \n",
       "\n",
       "       feature_765  feature_766  feature_767   word_count     punc_num  \n",
       "count  2786.000000  2786.000000  2786.000000  2786.000000  2786.000000  \n",
       "mean      0.430616     0.090058    -0.063190    29.622039     7.235822  \n",
       "std       0.375159     0.568711     0.307806    10.283190     3.986695  \n",
       "min      -1.348983    -1.604238    -0.957339     7.000000     0.000000  \n",
       "25%       0.186517    -0.297254    -0.282540    22.000000     4.000000  \n",
       "50%       0.455588     0.036784    -0.076090    30.000000     7.000000  \n",
       "75%       0.688687     0.421393     0.134562    38.000000    10.000000  \n",
       "max       1.619909     2.709688     1.624837    57.000000    39.000000  \n",
       "\n",
       "[8 rows x 771 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()\n",
    "#test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f737e71-c61a-422d-b556-0db80048951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming all columns except 'ID' and 'ind' are features\n",
    "features = [col for col in train_data.columns if col not in ['ID', 'ind']]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features of the training data\n",
    "train_data[features] = scaler.fit_transform(train_data[features])\n",
    "\n",
    "# Scale the features of the test data\n",
    "# Note: We only transform the test data using the scaler fitted on the training data\n",
    "test_data[features] = scaler.transform(test_data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35da951-25d1-480e-9e03-6c78d46d124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(train_data[features], train_data['ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91adb7a5-a635-4228-8a2d-9cd4df758319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores for each fold are: [0.224      0.23715415 0.2310757  0.27692308 0.23015873]\n",
      "Mean F1 score: 0.23986233089811818\n",
      "Accuracy scores for each fold are: [0.91296546 0.91341409 0.91341409 0.91565725 0.91292639]\n",
      "Mean accuracy score: 0.9136754532428337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation and compute the F1 score\n",
    "f1_scores = cross_val_score(clf, train_data[features], train_data['ind'], cv=5, scoring='f1')\n",
    "\n",
    "print(f\"F1 scores for each fold are: {f1_scores}\")\n",
    "print(f\"Mean F1 score: {f1_scores.mean()}\")\n",
    "\n",
    "# Perform cross-validation and compute the accuracy\n",
    "accuracy_scores = cross_val_score(clf, train_data[features], train_data['ind'], cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Accuracy scores for each fold are: {accuracy_scores}\")\n",
    "print(f\"Mean accuracy score: {accuracy_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203afd7f-2b49-4ec8-9cc3-6a836c00fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 17:37:20.546451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 17:37:31.969599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9647 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2024-01-08 17:37:31.971050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9647 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "2024-01-08 17:37:31.972253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9647 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:87:00.0, compute capability: 7.5\n",
      "2024-01-08 17:37:31.973429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 7391 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2024-01-08 17:37:31.974620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 7391 MB memory:  -> device: 4, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2024-01-08 17:37:31.975802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 7391 MB memory:  -> device: 5, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "2024-01-08 17:37:31.977064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 7391 MB memory:  -> device: 6, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 17:37:34.717080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80a8043250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-08 17:37:34.717131: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-01-08 17:37:34.717142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-01-08 17:37:34.717151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2024-01-08 17:37:34.717160: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-08 17:37:34.717169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-08 17:37:34.717177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-08 17:37:34.717186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-01-08 17:37:34.726259: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-08 17:37:34.795351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2024-01-08 17:37:34.905436: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-08 17:37:35.023284: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 5s 8ms/step - loss: 0.3236 - accuracy: 0.8961 - f1_score: 0.2445 - val_loss: 0.2090 - val_accuracy: 0.9349 - val_f1_score: 0.4510\n",
      "Epoch 2/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.2435 - accuracy: 0.9186 - f1_score: 0.4051 - val_loss: 0.1788 - val_accuracy: 0.9390 - val_f1_score: 0.4841\n",
      "Epoch 3/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.2080 - accuracy: 0.9311 - f1_score: 0.4625 - val_loss: 0.1723 - val_accuracy: 0.9435 - val_f1_score: 0.5477\n",
      "Epoch 4/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1924 - accuracy: 0.9353 - f1_score: 0.5078 - val_loss: 0.1715 - val_accuracy: 0.9439 - val_f1_score: 0.5601\n",
      "Epoch 5/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1832 - accuracy: 0.9392 - f1_score: 0.5254 - val_loss: 0.1565 - val_accuracy: 0.9489 - val_f1_score: 0.5865\n",
      "Epoch 6/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1682 - accuracy: 0.9403 - f1_score: 0.5423 - val_loss: 0.1564 - val_accuracy: 0.9529 - val_f1_score: 0.6263\n",
      "Epoch 7/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1591 - accuracy: 0.9441 - f1_score: 0.5883 - val_loss: 0.1584 - val_accuracy: 0.9502 - val_f1_score: 0.5859\n",
      "Epoch 8/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1508 - accuracy: 0.9490 - f1_score: 0.5960 - val_loss: 0.1557 - val_accuracy: 0.9511 - val_f1_score: 0.6193\n",
      "Epoch 9/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1469 - accuracy: 0.9475 - f1_score: 0.6064 - val_loss: 0.1535 - val_accuracy: 0.9533 - val_f1_score: 0.6180\n",
      "Epoch 10/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1370 - accuracy: 0.9503 - f1_score: 0.6069 - val_loss: 0.1625 - val_accuracy: 0.9498 - val_f1_score: 0.6137\n",
      "Epoch 11/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1344 - accuracy: 0.9537 - f1_score: 0.6430 - val_loss: 0.1544 - val_accuracy: 0.9511 - val_f1_score: 0.6117\n",
      "Epoch 12/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1324 - accuracy: 0.9508 - f1_score: 0.6154 - val_loss: 0.1577 - val_accuracy: 0.9493 - val_f1_score: 0.6316\n",
      "Epoch 13/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1198 - accuracy: 0.9589 - f1_score: 0.6852 - val_loss: 0.1601 - val_accuracy: 0.9542 - val_f1_score: 0.6623\n",
      "Epoch 14/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1172 - accuracy: 0.9580 - f1_score: 0.6823 - val_loss: 0.1630 - val_accuracy: 0.9533 - val_f1_score: 0.6291\n",
      "Epoch 15/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.1206 - accuracy: 0.9585 - f1_score: 0.6738 - val_loss: 0.1695 - val_accuracy: 0.9480 - val_f1_score: 0.5956\n",
      "Epoch 16/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1147 - accuracy: 0.9589 - f1_score: 0.6841 - val_loss: 0.1606 - val_accuracy: 0.9520 - val_f1_score: 0.6052\n",
      "Epoch 17/30\n",
      "279/279 [==============================] - 2s 7ms/step - loss: 0.1076 - accuracy: 0.9615 - f1_score: 0.6980 - val_loss: 0.1600 - val_accuracy: 0.9511 - val_f1_score: 0.6216\n",
      "Epoch 18/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0999 - accuracy: 0.9630 - f1_score: 0.7157 - val_loss: 0.1790 - val_accuracy: 0.9502 - val_f1_score: 0.6168\n",
      "Epoch 19/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0985 - accuracy: 0.9630 - f1_score: 0.7450 - val_loss: 0.1768 - val_accuracy: 0.9533 - val_f1_score: 0.6635\n",
      "Epoch 20/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9655 - f1_score: 0.7509 - val_loss: 0.1769 - val_accuracy: 0.9529 - val_f1_score: 0.6611\n",
      "Epoch 21/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0942 - accuracy: 0.9656 - f1_score: 0.7221 - val_loss: 0.1812 - val_accuracy: 0.9520 - val_f1_score: 0.6579\n",
      "Epoch 22/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0957 - accuracy: 0.9646 - f1_score: 0.7409 - val_loss: 0.1802 - val_accuracy: 0.9493 - val_f1_score: 0.6136\n",
      "Epoch 23/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0878 - accuracy: 0.9667 - f1_score: 0.7704 - val_loss: 0.1919 - val_accuracy: 0.9538 - val_f1_score: 0.6596\n",
      "Epoch 24/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0889 - accuracy: 0.9666 - f1_score: 0.7368 - val_loss: 0.1980 - val_accuracy: 0.9507 - val_f1_score: 0.6458\n",
      "Epoch 25/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0814 - accuracy: 0.9690 - f1_score: 0.7630 - val_loss: 0.1817 - val_accuracy: 0.9538 - val_f1_score: 0.6664\n",
      "Epoch 26/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0771 - accuracy: 0.9702 - f1_score: 0.7779 - val_loss: 0.2189 - val_accuracy: 0.9471 - val_f1_score: 0.6139\n",
      "Epoch 27/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0811 - accuracy: 0.9692 - f1_score: 0.7803 - val_loss: 0.2045 - val_accuracy: 0.9542 - val_f1_score: 0.6507\n",
      "Epoch 28/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0753 - accuracy: 0.9724 - f1_score: 0.7810 - val_loss: 0.2267 - val_accuracy: 0.9484 - val_f1_score: 0.6326\n",
      "Epoch 29/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0725 - accuracy: 0.9717 - f1_score: 0.7856 - val_loss: 0.2043 - val_accuracy: 0.9498 - val_f1_score: 0.6339\n",
      "Epoch 30/30\n",
      "279/279 [==============================] - 2s 6ms/step - loss: 0.0724 - accuracy: 0.9727 - f1_score: 0.7866 - val_loss: 0.2157 - val_accuracy: 0.9542 - val_f1_score: 0.6853\n",
      "70/70 [==============================] - 0s 2ms/step\n",
      "F1 Score on Validation Data:  0.8935064935064936\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Define a custom F1 score metric\n",
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "#Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=len(features)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(512, activation='relu', input_dim=len(features), kernel_regularizer=l2(0.01)),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     # tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     # tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_score])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(\n",
    "    train_data[features], train_data['ind'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data[features], train_data['ind'], epochs=30, batch_size=32, validation_split=0.20)\n",
    "\n",
    "# Predict on validation set\n",
    "validation_predictions = model.predict(validation_features)\n",
    "\n",
    "# Calculate F1 Score on Validation Data\n",
    "validation_f1_score = sklearn_f1_score(validation_labels, validation_predictions.round())\n",
    "print(\"F1 Score on Validation Data: \", validation_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd4bd325-2035-4d68-b8fb-4e6e32871ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  ind\n",
       "0   1    0\n",
       "1   2    0\n",
       "2   3    1\n",
       "3   4    0\n",
       "4   5    0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'test_data' is your test set DataFrame and the model is already trained\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(test_data[features])\n",
    "\n",
    "# Round predictions to 0 or 1 since 'ind' is a binary variable\n",
    "test_predictions_rounded = test_predictions.round().astype(int)\n",
    "\n",
    "# Create a DataFrame for the output\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': test_data['ID'],  # Assuming 'ID' is the column name for IDs in your test set\n",
    "    'ind': test_predictions_rounded.flatten()  # Flatten to convert from 2D to 1D\n",
    "})\n",
    "\n",
    "# Display the output DataFrame to ensure it's correct\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dda80cb-12a7-4098-bfdb-6c58eb2e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f9414-157f-4b97-9c50-8debed41df0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
