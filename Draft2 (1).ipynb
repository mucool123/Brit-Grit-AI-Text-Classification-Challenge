{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf5a3a-1ebc-4b23-9210-7f025e19b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 19:54:39.370093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae924763c78847e7a72fcd65bb210918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9619d4d36f48ca89f10a3acbbfc4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876b6a7aa5004249b91c9ae77da5e5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]2023-12-16 19:55:29.578489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9267 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "  1%|          | 1/112 [00:26<49:37, 26.82s/it]2023-12-16 19:55:29.579909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9267 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "2023-12-16 19:55:29.581107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9267 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:87:00.0, compute capability: 7.5\n",
      "2023-12-16 19:55:29.582299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 7081 MB memory:  -> device: 3, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "2023-12-16 19:55:29.583485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 7081 MB memory:  -> device: 4, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2023-12-16 19:55:29.584654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 7081 MB memory:  -> device: 5, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:83:00.0, compute capability: 6.1\n",
      "2023-12-16 19:55:29.585838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 7081 MB memory:  -> device: 6, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1\n",
      " 79%|███████▉  | 89/112 [09:00<02:14,  5.83s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('training_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')\n",
    "\n",
    "# Combine all features into a single text column\n",
    "features = [col for col in train_data.columns if col not in ['ID', 'ind']]\n",
    "train_data['combined_text'] = train_data[features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "test_data['combined_text'] = test_data[features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Initialize the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def batch_tokenize(texts, tokenizer, batch_size=100):\n",
    "    tokenized_batches = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tokenized = tokenizer(batch, truncation=True, padding=True, max_length=64, return_tensors='tf')\n",
    "        tokenized_batches.append(tokenized)\n",
    "    return tokenized_batches\n",
    "\n",
    "# Tokenize data in batches\n",
    "train_tokenized_batches = batch_tokenize(list(train_data['combined_text']), tokenizer)\n",
    "\n",
    "# Concatenate the tokenized batches\n",
    "def concatenate_batches(tokenized_batches):\n",
    "    concatenated_encodings = {key: [] for key in tokenized_batches[0].keys()}\n",
    "    for batch in tokenized_batches:\n",
    "        for key in batch.keys():\n",
    "            concatenated_encodings[key].extend(batch[key])\n",
    "    return concatenated_encodings\n",
    "\n",
    "# Concatenate train tokenized batches\n",
    "train_encodings = concatenate_batches(train_tokenized_batches)\n",
    "\n",
    "# Split training data for validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_encodings, train_data['ind'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Prepare training and validation datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_texts), train_labels)).shuffle(1000).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_texts), val_labels)).batch(32)\n",
    "\n",
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "\n",
    "# Define DistilBERT configuration\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define mirrored strategy for multi-GPU training\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope():\n",
    "    # Initialize model with specified configuration\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Custom F1 score metric\n",
    "def f1_metric(y_true, y_pred):\n",
    "    return f1_score(y_true, tf.round(tf.nn.sigmoid(y_pred)))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=3)\n",
    "\n",
    "# Tokenize test data\n",
    "test_tokenized_batches = batch_tokenize(list(test_data['combined_text']), tokenizer)\n",
    "test_encodings = concatenate_batches(test_tokenized_batches)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings))).batch(32)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(test_dataset)['logits']\n",
    "\n",
    "# Convert logits to 0 or 1 predictions\n",
    "test_preds = tf.nn.sigmoid(test_predictions)\n",
    "test_preds = tf.where(test_preds < 0.5, 0, 1)\n",
    "\n",
    "# Create a DataFrame for the output\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    'ind': test_preds.numpy().flatten()\n",
    "})\n",
    "\n",
    "# Display the output DataFrame to ensure it's correct\n",
    "print(output_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d666bde-b8a7-4d10-9345-e456b10f8a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
